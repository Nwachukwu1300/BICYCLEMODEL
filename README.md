# Bicycle Demand Prediction -85% grade in uni

This project trains several regression models (linear, random forest, gradient boosting, and MLP) to predict hourly bicycle usage. The workflow lives in `MLnotebook.ipynb`, which covers data cleaning, feature engineering (seasonal signals, lagged demand, rolling stats), model training, and evaluation.

## Demo video

https://livecoventryac-my.sharepoint.com/personal/nwachukwum_uni_coventry_ac_uk/_layouts/15/stream.aspx?id=%2Fpersonal%2Fnwachukwum%5Funi%5Fcoventry%5Fac%5Fuk%2FDocuments%2Fbicycle%5Fmodel%5Fvideo%2Emov&nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJTdHJlYW1XZWJBcHAiLCJyZWZlcnJhbFZpZXciOiJTaGFyZURpYWxvZy1MaW5rIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXcifX0&ga=1&referrer=StreamWebApp%2EWeb&referrerScenario=AddressBarCopied%2Eview%2E87d5fa85%2D927d%2D4ce4%2D9f0c%2D9094d257f063


## Dataset

Paste the dataset source URL here so future runs know where to fetch it:

https://www.openml.org/search?type=data&sort=runs&id=42712&status=active) 

Place the downloaded file (or derived train/test splits) inside `data/` and update the notebook paths if you change the filenames.

## Repository Layout

- `MLnotebook.ipynb` – end-to-end exploration, feature engineering, training, and evaluation.
- `data/` – cleaned dataset (`clean_bike.csv`) plus prepared train/test splits and a `data_summary.json`.
- `models/` – serialized versions of the trained models (basic baselines and tuned variants).
- `results/` – plots, prediction CSVs, and metrics JSON files generated by the notebook.

## Getting Started

1. Create a virtual environment (`python -m venv .venv && source .venv/bin/activate`) and install the standard data science stack (pandas, numpy, scikit-learn, xgboost, matplotlib, seaborn, shap, etc.).
2. Launch Jupyter (`jupyter lab` or `jupyter notebook`) from the repo root and open `MLnotebook.ipynb`.
3. Run the cells in order. Adjust hyperparameters and feature blocks in the notebook to experiment with different model flavors.

## Reproducing Results

Running the notebook will regenerate:

- Trained model artifacts in `models/`.
- Metrics JSONs and comparison plots in `results/`.
- Prediction CSVs for downstream analysis or visualization.

Feel free to tailor the feature engineering steps or try additional models—just keep the dataset link above up to date so collaborators can access the same raw data.


## Notebook Structure

The `MLnotebook.ipynb` follows a systematic pipeline from data preprocessing through model evaluation:

### 1. Data Preprocessing & Feature Engineering
- Data loading from OpenML Bike Sharing Dataset
- Exploratory data analysis and visualization
- Datetime feature creation
- Cyclical encoding (hour, month)
- One-hot encoding of categorical variables
- Feature engineering: lag features, rolling statistics, interaction terms
- Train/test temporal split (70/30)

### 2. Linear Regression Baseline Model
- Pipeline with StandardScaler
- GridSearchCV with TimeSeriesSplit cross-validation
- Hyperparameter tuning (LinearRegression vs Ridge)
- Performance evaluation and visualization
- Feature coefficients analysis

### 3. Random Forest Regression Model
- RandomizedSearchCV for hyperparameter optimization
- Feature importance analysis
- SHAP (SHapley Additive exPlanations) for model interpretability
- Performance metrics and residual analysis

### 4. XGBoost Regression Model
- Gradient boosting with histogram-based tree construction
- RandomizedSearchCV for learning rate, tree depth, and regularization tuning
- SHAP analysis for feature contribution
- Prediction visualization and error analysis

### 5. Multi-Layer Perceptron (Neural Network)
- Pipeline with StandardScaler for input normalization
- RandomizedSearchCV for architecture and hyperparameter optimization
- Training history and learning curves
- Residual distribution analysis

### 6. Model Comparison
- Basic (untuned) models with default parameters
- Feature engineering impact assessment (original vs engineered features)
- Tuned vs basic model performance comparison
- Comprehensive metrics evaluation (MAE, RMSE, R²)
